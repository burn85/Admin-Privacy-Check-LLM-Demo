# -*- coding: utf-8 -*-
"""
==============================================================================
[í¬íŠ¸í´ë¦¬ì˜¤] ê°œì¸ì •ë³´ ì²˜ë¦¬ ì‹œìŠ¤í…œ(Admin Tool) ì ê²€ ê²°ê³¼ ë¶„ì„ ë° ê°œì„ ì‚¬í•­ ì œì•ˆ (RAG + LLM)
==============================================================================

**í”„ë¡œì íŠ¸ ê°œìš”:**
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê´€ë¦¬ì ë„êµ¬(Admin Tool)ì˜ í™”ë©´ ì •ë³´ë¥¼ ê°€ì •í•œ JSON ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„,
ê°œì¸ì •ë³´ ì²˜ë¦¬ í˜„í™©ì„ ë¶„ì„í•˜ê³  ì ì¬ì  ìœ„í—˜ ìš”ì†Œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. ì´ëŠ” ì¼ë°˜ì ì¸
ì •ë³´ë³´í˜¸ ë° ê°œì¸ì •ë³´ë³´í˜¸ ì ê²€ í™œë™ì˜ ì¼ë¶€ë¥¼ ìë™í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
ì‹ë³„ëœ ìœ„í—˜ì— ëŒ€í•´ RAG(Retrieval-Augmented Generation) ê¸°ìˆ ì„ í™œìš©, ë¡œì»¬ì— ì €ì¥ëœ
ê´€ë ¨ ë¬¸ì„œ(ì˜ˆ: ë²•ê·œ, ê°€ì´ë“œë¼ì¸, ë‚´ë¶€ ì •ì±…)ë¥¼ ì°¸ì¡°í•˜ì—¬ LLMì´ êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆì„
ì œì•ˆí•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ëŠ” AI ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ë³´ì•ˆ ì ê²€ ë° ì»¨ì„¤íŒ… ì—…ë¬´ì˜ íš¨ìœ¨ì„±ì„
ë†’ì´ëŠ” ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•©ë‹ˆë‹¤. ìµœì¢… ê²°ê³¼ëŠ” HTML ë³´ê³ ì„œë¡œ ìƒì„±ë˜ì–´ ì ê²€ ê²°ê³¼ ë°
ê°œì„  ì œì•ˆì„ ëª…í™•í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
1.  **JSON ë°ì´í„° ë¶„ì„:** Admin Tool í™”ë©´ ì •ë³´(í•„ë“œ, ì•¡ì…˜) íŒŒì‹±í•˜ì—¬ ê°œì¸ì •ë³´ ë¯¼ê°ë„
    ë° ì‹œìŠ¤í…œ ì¤‘ìš”ë„ ì‚°ì • (ì˜ˆì‹œ ë¡œì§).
    (*ì£¼ì˜: ì‹¤ì œ ì ìš© ì‹œ ê´€ë ¨ ë²•ê·œ ë° ë‚´ë¶€ ì •ì±… ê¸°ë°˜ ì „ë¬¸ê°€ ê²€í† /ìˆ˜ì • í•„ìˆ˜*)
2.  **ì ì¬ ìœ„í—˜ ì‹ë³„:** ë¶„ì„ ê²°ê³¼ ê¸°ë°˜, ê°œì¸ì •ë³´ë³´í˜¸ ê´€ì ì˜ ìœ„í—˜ ìš”ì†Œ ì‹ë³„ (ì˜ˆì‹œ ë¡œì§).
3.  **ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰ (RAG):** ë¡œì»¬ ë¬¸ì„œ(`rag_documents`)ì—ì„œ ìœ„í—˜ ìš”ì†Œ ê´€ë ¨ ë‚´ìš©ì„
    ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰.
4.  **ê°œì„  ì œì•ˆ ìƒì„± (Generation):** ê²€ìƒ‰ëœ ì •ë³´(Context)ì™€ ìœ„í—˜ ìš”ì†Œë¥¼ LLMì—
    ì „ë‹¬í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ ìƒì„± ìš”ì²­ ("assistant" ë§ˆì»¤ ê¸°ë°˜ í›„ì²˜ë¦¬ ì ìš©).
5.  **ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±:** ë¶„ì„ ê²°ê³¼, AI ìƒì„± ê°œì„  ì œì•ˆ, ì°¸ê³  ë¬¸ì„œë¥¼ í¬í•¨í•œ HTML ë³´ê³ ì„œ ìƒì„±.

**í•µì‹¬ ê¸°ìˆ :**
- LLM (ì˜ˆ: Naver HyperCLOVA X Seed)
- RAG, Text Embedding (ì˜ˆ: BAAI/bge-m3), Vector Search (FAISS)
- Frameworks: Transformers, LangChain, PyTorch
- Configuration: python-dotenv

**í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨ ì„¤ëª…:**
- ì •ë³´ ì‹œìŠ¤í…œ ì ê²€, ìœ„í—˜ ë¶„ì„, ê°œì„ ì•ˆ ë„ì¶œ ê³¼ì •ì„ ìë™í™”í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬
  ì—…ë¬´ íš¨ìœ¨í™” ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.
- ìµœì‹  AI ê¸°ìˆ (RAG, LLM)ì„ ì‹¤ì œ ë³´ì•ˆ/ê°œì¸ì •ë³´ë³´í˜¸ ì‹¤ë¬´ì— ì ìš©í•˜ëŠ” ëŠ¥ë ¥ê³¼
  End-to-End íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê²½í—˜ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- ë¶„ì„ ë¡œì§ì˜ í•œê³„ì™€ ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš”ì„±ì„ ëª…í™•íˆ ì¸ì§€í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- ìƒì„¸ ì£¼ì„ì„ í†µí•´ ì½”ë“œì˜ ëª©ì ê³¼ ê¸°ìˆ ì  êµ¬í˜„ ë‚´ìš©ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
"""

# --- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
import torch
import warnings
import os
import json
import re
import html
import traceback
from dotenv import load_dotenv # .env íŒŒì¼ ë¡œë”©ìš©
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime # ë³´ê³ ì„œ ìƒì„± ì‹œê°„ ê¸°ë¡ìš©

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
# ì–‘ìí™” ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ: from transformers import BitsAndBytesConfig
from langchain_huggingface import HuggingFacePipeline
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.document_loaders import DirectoryLoader, UnstructuredMarkdownLoader, PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel
from langchain_core.output_parsers import StrOutputParser
from langchain.docstore.document import Document

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore")

# --- 2. ì£¼ìš” ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---
load_dotenv() # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ

# Hugging Face ëª¨ë¸ ID (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
LLM_MODEL_ID: str = os.getenv("LLM_MODEL_ID", "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B")
EMBEDDING_MODEL_ID: str = os.getenv("EMBEDDING_MODEL_ID", "BAAI/bge-m3")

# ê²½ë¡œ ì„¤ì •
RAG_DATA_DIR: str = os.getenv("RAG_DATA_DIR", "rag_documents")
INPUT_JSON_FILE: str = os.getenv("INPUT_JSON_FILE", "input_admin_data.json")
OUTPUT_DIR: str = os.getenv("OUTPUT_DIR", "reports") # ë³´ê³ ì„œ ì €ì¥ ë””ë ‰í† ë¦¬

# ì—°ì‚° ì¥ì¹˜ ì„¤ì •
DEVICE: torch.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# RAG Retriever ì„¤ì •
RETRIEVER_K: int = int(os.getenv("RETRIEVER_K", 3)) # ê²€ìƒ‰í•  ì²­í¬ ìˆ˜

# LLM ìƒì„± íŒŒë¼ë¯¸í„°
LLM_MAX_NEW_TOKENS: int = int(os.getenv("LLM_MAX_NEW_TOKENS", 1024))
LLM_TEMPERATURE: float = float(os.getenv("LLM_TEMPERATURE", 0.5))
LLM_TOP_P: float = float(os.getenv("LLM_TOP_P", 0.95))
LLM_REPETITION_PENALTY: float = float(os.getenv("LLM_REPETITION_PENALTY", 1.15))

# í…ìŠ¤íŠ¸ ë¶„í•  íŒŒë¼ë¯¸í„°
CHUNK_SIZE: int = int(os.getenv("CHUNK_SIZE", 1000))
CHUNK_OVERLAP: int = int(os.getenv("CHUNK_OVERLAP", 100))

# LLM ì¶œë ¥ íŒŒì‹±ìš© ë§ˆì»¤ (LLM ì¶œë ¥ì„ ë¶„ë¦¬í•  ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©)
ASSISTANT_MARKER: str = "assistant"

# --- 3. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ ---
@torch.no_grad()
def load_models() -> Tuple[Optional[HuggingFacePipeline], Optional[HuggingFaceEmbeddings], Optional[AutoTokenizer]]:
    """LLM, ì„ë² ë”© ëª¨ë¸, í† í¬ë‚˜ì´ì € ë¡œë“œ ë° ì„¤ì •."""
    print("-" * 50)
    print("ëª¨ë¸ ë¡œë”© ì‹œì‘...")
    print(f"  LLM: {LLM_MODEL_ID}")
    print(f"  Embedding: {EMBEDDING_MODEL_ID}")
    print(f"  Device: {DEVICE}")
    print("-" * 50)
    llm_pipeline, embedding_model, tokenizer = None, None, None
    try:
        # --- LLM ë¡œë”© ---
        print(f"LLM ë¡œë”© ì¤‘...")
        if "naver-hyperclovax" in LLM_MODEL_ID:
            print("    ì•Œë¦¼: Naver ëª¨ë¸ ì‚¬ìš© ì‹œ Hugging Face ë¡œê·¸ì¸ ë° ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_ID)

        model_load_kwargs = {
            "torch_dtype": torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,
            "device_map": "auto",
            "trust_remote_code": True
        }
        # (ì˜µì…˜) ì–‘ìí™” ì„¤ì • (VRAM ë¶€ì¡± ì‹œ)
        # quantization_config = BitsAndBytesConfig(load_in_8bit=True)
        # model_load_kwargs["quantization_config"] = quantization_config

        model = AutoModelForCausalLM.from_pretrained(LLM_MODEL_ID, **model_load_kwargs)
        print("    LLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        # --- Stop Token ì„¤ì • ---
        stop_strings = ["<|endofturn|>", "<|stop|>"] # ëª¨ë¸ë³„ ê¶Œì¥ Stop String
        stop_token_ids = []
        valid_stop_tokens = []
        for token_str in stop_strings:
            token_ids = tokenizer.encode(token_str, add_special_tokens=False)
            if token_ids:
                stop_token_ids.extend(token_ids)
                valid_stop_tokens.append(token_str)

        print(f"    ëª…ì‹œì  Stop Strings ì„¤ì • ì‹œë„: {stop_strings}")
        print(f"    -> ë³€í™˜ëœ Stop Token IDs: {stop_token_ids}")
        print(f"    -> ìœ íš¨í•˜ê²Œ ì¸ì‹ëœ Stop Strings: {valid_stop_tokens}")

        if model.config.eos_token_id and model.config.eos_token_id not in stop_token_ids:
            stop_token_ids.append(model.config.eos_token_id)
            print(f"    ëª¨ë¸ ê¸°ë³¸ EOS Token ID ({model.config.eos_token_id}) ì¶”ê°€ë¨.")

        active_stop_token_ids = list(set(stop_token_ids))
        if not active_stop_token_ids:
             print("    ê²½ê³ : ìœ íš¨í•œ Stop Token IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print(f"    ìµœì¢… ì‚¬ìš© Stop Token IDs: {active_stop_token_ids}")


        # --- LLM íŒŒì´í”„ë¼ì¸ ìƒì„± ---
        pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=LLM_MAX_NEW_TOKENS,
            temperature=LLM_TEMPERATURE,
            top_p=LLM_TOP_P,
            repetition_penalty=LLM_REPETITION_PENALTY,
            do_sample=True,
            eos_token_id=active_stop_token_ids
        )
        llm_pipeline = HuggingFacePipeline(pipeline=pipe)
        print("    LLM Text Generation Pipeline ìƒì„± ì™„ë£Œ.")

        # --- ì„ë² ë”© ëª¨ë¸ ë¡œë”© ---
        print(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_ID,
            model_kwargs={'device': DEVICE},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("    ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
        print("-" * 50)
        print("ëª¨ë¸ ë¡œë”© ì„±ê³µ.")
        print("-" * 50)
        return llm_pipeline, embedding_model, tokenizer

    except ImportError as ie:
        print(f"ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”©ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶€ì¬. {ie}")
        print("    ì„¤ì¹˜ ì˜ˆì‹œ: pip install torch transformers accelerate langchain sentence-transformers faiss-gpu python-dotenv pypdf unstructured[md]")
        return None, None, None
    except Exception as e:
        print(f"ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œ ë°œìƒ - {e}")
        print("-" * 30)
        traceback.print_exc()
        print("-" * 30)
        if "401" in str(e) or "requires you to be authenticated" in str(e):
             print("    íŒíŠ¸: Hugging Face ë¡œê·¸ì¸ ë˜ëŠ” ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif "out of memory" in str(e).lower():
             print("    íŒíŠ¸: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±(OOM). ëª¨ë¸ ì–‘ìí™”(8bit/4bit) ì‚¬ìš©ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        return None, None, None

# --- 4. RAG ì„¤ì • í•¨ìˆ˜ ---
def setup_rag_retriever(embedding_model: HuggingFaceEmbeddings) -> Optional[Any]:
    """ë¬¸ì„œ ë¡œë“œ, ë¶„í• , ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ê¸°ë°˜ Retriever ì„¤ì •."""
    print("\n" + "-" * 50)
    print("RAG ì„¤ì • ì‹œì‘ (ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰ ì¤€ë¹„)...")
    print(f"  ë¬¸ì„œ ë””ë ‰í† ë¦¬: {RAG_DATA_DIR}")
    print("-" * 50)

    if not os.path.exists(RAG_DATA_DIR):
        print(f"ê²½ê³ : RAG ë¬¸ì„œ ë””ë ‰í† ë¦¬ '{RAG_DATA_DIR}' ì—†ìŒ. ìƒì„± ì‹œë„...")
        try:
            os.makedirs(RAG_DATA_DIR)
            print(f"    -> '{RAG_DATA_DIR}' ìƒì„± ì™„ë£Œ.")
            print(f"    -> ì¤‘ìš”: í•´ë‹¹ ë””ë ‰í† ë¦¬ì— ê´€ë ¨ ë²•ê·œ, ê°€ì´ë“œë¼ì¸ ë“± ë¬¸ì„œë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
            print(f"    -> í˜„ì¬ ë¬¸ì„œê°€ ì—†ìœ¼ë¯€ë¡œ RAG ê¸°ëŠ¥ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        except OSError as e:
            print(f"    ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ - {e}. RAG ì„¤ì • ì¤‘ë‹¨.")
            return None
        return None

    supported_loaders = {
        "**/*.md": UnstructuredMarkdownLoader,
        "**/*.pdf": PyPDFLoader
    }
    all_documents = []
    print("ë¬¸ì„œ ë¡œë”© ì‹œì‘ (ì§€ì› í¬ë§·: MD, PDF)")
    found_files = False
    for glob_pattern, loader_cls in supported_loaders.items():
        file_type = glob_pattern.split('.')[-1].upper()
        try:
            loader = DirectoryLoader(
                RAG_DATA_DIR,
                glob=glob_pattern,
                loader_cls=loader_cls,
                show_progress=False,
                use_multithreading=True,
                silent_errors=True
            )
            loaded_docs = loader.load()
            if loaded_docs:
                print(f"    - {len(loaded_docs)}ê°œì˜ {file_type} ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ.")
                all_documents.extend(loaded_docs)
                found_files = True
        except ImportError as ie:
             print(f"    ê²½ê³ : {file_type} ë¡œë”© ë¶ˆê°€ (í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶€ì¬) - {ie}")
             if file_type == 'PDF': print("         `pip install pypdf` í•„ìš”")
             if file_type == 'MD': print("         `pip install unstructured` í•„ìš”")
        except Exception as e:
            print(f"    ì˜¤ë¥˜: {file_type} ë¡œë”© ì¤‘ ë¬¸ì œ ë°œìƒ - {e}")

    if not found_files:
        print("ê²½ê³ : RAG ë¬¸ì„œ ë””ë ‰í† ë¦¬ì— ë¡œë“œ ê°€ëŠ¥í•œ ë¬¸ì„œ(MD, PDF)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("     RAG ê¸°ë°˜ ê°œì„  ì œì•ˆ ìƒì„±ì´ ì œí•œë©ë‹ˆë‹¤.")
        return None
    print(f"ì´ {len(all_documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ.")

    print("í…ìŠ¤íŠ¸ ë¶„í•  ì§„í–‰...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        length_function=len,
        is_separator_regex=False,
    )
    split_docs = text_splitter.split_documents(all_documents)
    if not split_docs:
        print("ì˜¤ë¥˜: ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. RAG ì„¤ì • ì¤‘ë‹¨.")
        return None
    print(f"ì´ {len(split_docs)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ (Chunk Size: {CHUNK_SIZE}, Overlap: {CHUNK_OVERLAP}).")

    print("ë²¡í„° ì €ì¥ì†Œ(FAISS) ìƒì„± ë° ì„ë² ë”© ì‹œì‘...")
    print("    (ë¬¸ì„œ ì–‘ì— ë”°ë¼ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    try:
        vectorstore = FAISS.from_documents(split_docs, embedding_model)
        print("    ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ.")
        retriever = vectorstore.as_retriever(search_kwargs={'k': RETRIEVER_K})
        print(f"Retriever ì„¤ì • ì™„ë£Œ (ìœ ì‚¬ë„ ìƒìœ„ {RETRIEVER_K}ê°œ ì²­í¬ ê²€ìƒ‰).")
        print("-" * 50)
        print("RAG ì„¤ì • ì„±ê³µ.")
        print("-" * 50)
        return retriever
    except Exception as e:
        print(f"ì˜¤ë¥˜: ë²¡í„° ì €ì¥ì†Œ ë˜ëŠ” Retriever ìƒì„± ì‹¤íŒ¨ - {e}")
        traceback.print_exc()
        return None

# --- 5. ë¶„ì„ ë¡œì§ í•¨ìˆ˜ë“¤ ---
# ============================================================
# !!! ì¤‘ìš” ê²½ê³  / í¬íŠ¸í´ë¦¬ì˜¤ ì„¤ëª… !!!
# ì•„ë˜ 3ê°œ í•¨ìˆ˜ëŠ” ì •ë³´ ì‹œìŠ¤í…œ ì ê²€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•œ
# **ë‹¨ìˆœí™”ëœ ì˜ˆì‹œ ë¡œì§**ì…ë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ê´€ë ¨ ë²•ê·œ(ì˜ˆ: ê°œì¸ì •ë³´ë³´í˜¸ë²•),
# ë‚´ë¶€ ì •ì±… ë° ê°€ì´ë“œë¼ì¸, ì„œë¹„ìŠ¤ íŠ¹ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬
# **ë°˜ë“œì‹œ ì „ë¬¸ê°€ì˜ ê²€í† ë¥¼ ê±°ì³ ì •êµí•˜ê²Œ ì„¤ê³„ ë° êµ¬í˜„**ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
# ============================================================

def analyze_pii_grade(fields: List[Dict[str, Any]]) -> str:
    """Admin Tool í™”ë©´ í•„ë“œ ë¶„ì„ -> ì²˜ë¦¬ ê°œì¸ì •ë³´ ë¯¼ê°ë„ ë“±ê¸‰ ì‚°ì • (ì˜ˆì‹œ ë¡œì§)."""
    high_sensitivity_types = {
        "resident_registration_number", "passport_number", "driver_license_number",
        "credit_card_number", "bank_account_number",
        "health_info", "genetic_info",
        "name", "phone", "email", "address", "id"
    }
    medium_sensitivity_types = {
        "birthdate", "gender", "nationality",
        "ip_address", "device_id", "service_use_record"
    }
    has_unmasked_high = False
    has_medium_or_masked_high = False
    if not fields: return "í•˜"
    for field in fields:
        if not field.get("visible", False): continue
        pii_type = field.get("pii_type", "unknown").lower()
        masked = field.get("masked", False)
        if pii_type in high_sensitivity_types:
            if not masked: has_unmasked_high = True; break
            else: has_medium_or_masked_high = True
        elif pii_type in medium_sensitivity_types:
            has_medium_or_masked_high = True
    if has_unmasked_high: return "ìƒ"
    elif has_medium_or_masked_high: return "ì¤‘"
    else: return "í•˜"

def analyze_system_importance(actions: List[Dict[str, Any]], pii_grade: str) -> str:
    """Admin Tool ê¸°ëŠ¥(Actions) ë° ê°œì¸ì •ë³´ ë“±ê¸‰ ê¸°ë°˜ -> ì‹œìŠ¤í…œ ì¤‘ìš”ë„ ì‚°ì • (ì˜ˆì‹œ ë¡œì§)."""
    high_risk_keywords = {"delete", "destroy", "remove", "bulk_download", "mass_update"}
    medium_risk_keywords = {"modify", "update", "download", "export", "view_unmasked"}
    highest_action_risk = "low"
    unencrypted_download_possible = False
    if not actions: return "ë‚®ìŒ"
    for action in actions:
        if not action.get("enabled", False): continue
        action_name_lower = action.get("action_name", "").lower()
        download_encryption = action.get("download_encryption")
        current_risk = "low"
        if any(keyword in action_name_lower for keyword in high_risk_keywords): current_risk = "high"
        elif any(keyword in action_name_lower for keyword in medium_risk_keywords): current_risk = "medium"
        if "download" in action_name_lower and download_encryption is None:
            unencrypted_download_possible = True
            current_risk = "high" if pii_grade in ["ìƒ", "ì¤‘"] else "medium"
        if current_risk == "high": highest_action_risk = "high"
        elif current_risk == "medium" and highest_action_risk == "low": highest_action_risk = "medium"

    calculated_importance = "ë‚®ìŒ"
    if pii_grade == "ìƒ":
        if highest_action_risk == "high": calculated_importance = "ë†’ìŒ"
        elif highest_action_risk == "medium": calculated_importance = "ì¤‘ê°„"
        else: calculated_importance = "ë‚®ìŒ"
    elif pii_grade == "ì¤‘":
        if highest_action_risk in ["high", "medium"]: calculated_importance = "ì¤‘ê°„"
        else: calculated_importance = "ë‚®ìŒ"
    else: # pii_grade == "í•˜"
        if highest_action_risk == "high": calculated_importance = "ì¤‘ê°„"
        else: calculated_importance = "ë‚®ìŒ"

    if unencrypted_download_possible and calculated_importance == "ë‚®ìŒ":
         calculated_importance = "ì¤‘ê°„" # ë¹„ì•”í˜¸í™” ë‹¤ìš´ë¡œë“œ ì‹œ ìµœì†Œ ì¤‘ê°„

    return calculated_importance

def identify_potential_issues(fields: List[Dict[str, Any]], actions: List[Dict[str, Any]]) -> List[str]:
    """Admin Tool í•„ë“œ/ì•¡ì…˜ ì •ë³´ ê¸°ë°˜ ì ì¬ì  ìœ„í—˜ ìš”ì†Œ ì‹ë³„ (ì˜ˆì‹œ ë¡œì§)."""
    issues = []
    high_sensitivity_types = {
        "resident_registration_number", "passport_number", "driver_license_number",
        "credit_card_number", "bank_account_number",
        "health_info", "genetic_info",
        "name", "phone", "email", "address", "id"
    }
    unmasked_sensitive_fields = [f"'{f.get('field_name', 'N/A')}' (ìœ í˜•: {f.get('pii_type', 'N/A')})" for f in fields if f.get("visible", True) and f.get("pii_type", "").lower() in high_sensitivity_types and not f.get("masked", False)]
    if unmasked_sensitive_fields: issues.append(f"ê³ ìœ„í—˜ ê°œì¸ì •ë³´ í•„ë“œ ({', '.join(unmasked_sensitive_fields)})ê°€ ë§ˆìŠ¤í‚¹ ì—†ì´ í™”ë©´ì— í‘œì‹œë©ë‹ˆë‹¤.")

    unencrypted_download_actions = [f"'{a.get('action_name', 'N/A')}' (ê¶Œí•œ: {a.get('required_permission', 'ì—†ìŒ')})" for a in actions if a.get("enabled", False) and "download" in a.get("action_name", "").lower() and a.get("download_encryption") is None]
    if unencrypted_download_actions: issues.append(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ ({', '.join(unencrypted_download_actions)})ì—ì„œ ì•”í˜¸í™” ì¡°ì¹˜ê°€ í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    high_risk_action_details = [f"'{a.get('action_name', 'N/A')}' (ê¶Œí•œ: {a.get('required_permission', 'ì—†ìŒ')})" for a in actions if a.get("enabled", False) and any(k in a.get("action_name", "").lower() for k in {"modify", "update", "delete", "destroy", "remove", "bulk", "mass"})]
    if high_risk_action_details: issues.append(f"ë°ì´í„° ëŒ€ëŸ‰/ìˆ˜ì •/ì‚­ì œ ë“± ê³ ìœ„í—˜ ê¸°ëŠ¥ ({', '.join(high_risk_action_details)})ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì ‘ê·¼ í†µì œ ë° ê°ì‚¬ ë¡œê·¸ ê°•í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    actions_without_permission = [f"'{a.get('action_name', 'N/A')}'" for a in actions if a.get("enabled", False) and not a.get("required_permission") and not any(k in a.get("action_name", "").lower() for k in ["close", "cancel", "list", "search", "view_list"])]
    if actions_without_permission: issues.append(f"ì¼ë¶€ ì¤‘ìš” ê¸°ëŠ¥({', '.join(actions_without_permission)})ì— í•„ìš”í•œ ì ‘ê·¼ ê¶Œí•œ ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    return issues


# --- 6. RAG ê¸°ë°˜ ê°œì„ ì‚¬í•­ ìƒì„± í•¨ìˆ˜ ---
def generate_improvement_suggestions(issues: List[str], retriever: Optional[Any], llm: HuggingFacePipeline, tokenizer: AutoTokenizer) -> List[str]:
    """ì‹ë³„ëœ ì´ìŠˆë³„ë¡œ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰, LLM í†µí•´ ê°œì„  ì œì•ˆ ìƒì„±."""
    print("\n" + "-" * 50)
    print("RAG + LLM ê¸°ë°˜ ê°œì„  ì œì•ˆ ìƒì„± ì‹œì‘...")
    print("-" * 50)

    if not retriever:
        print("ê²½ê³ : RAG Retrieverê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë¬¸ì„œ ì°¸ì¡° ê¸°ë°˜ ê°œì„  ì œì•ˆ ìƒì„± ë¶ˆê°€.")
        return [f"**[ë¬¸ì œì ]**{issue}|||**[ê°œì„  ì œì•ˆ]**(ì˜¤ë¥˜) ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´(Retriever ì—†ìŒ) ìë™ ì œì•ˆ ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.|||**[ì°¸ê³  ë¬¸ì„œ]**ì—†ìŒ" for issue in issues]

    if not issues:
        print("ì •ë³´: ì‹ë³„ëœ ì ì¬ ìœ„í—˜ ìš”ì†Œê°€ ì—†ì–´ ê°œì„  ì œì•ˆì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return []

    suggestions_with_sources = []

    # --- ChatPromptTemplate ì •ì˜ ---
    system_prompt = f"""ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ê°œì¸ì •ë³´ ì „ë¬¸ê°€ ë° ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ì ì¬ì  ìœ„í—˜ ìš”ì†Œ'ì™€ ê´€ë ¨ëœ 'ì°¸ê³  ë¬¸ì„œ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, ê°œë°œìì—ê²Œ í•´ë‹¹ ìœ„í—˜ì„ í•´ê²°í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆì„ 1-2ê°€ì§€ ì œì•ˆí•´ì•¼ í•©ë‹ˆë‹¤. ì œì•ˆ ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ê³ , í•„ìš”í•œ ê²½ìš° ê¸°ìˆ ì  ì¡°ì¹˜ì™€ ì •ì±…ì  ì¡°ì¹˜ë¥¼ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•˜ì„¸ìš”.

ë‹µë³€ì€ ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”:
[ê°œì„  ë°©ì•ˆ 1]
(ê°œì„  ë°©ì•ˆ 1ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…)

[ê°œì„  ë°©ì•ˆ 2]
(ê°œì„  ë°©ì•ˆ 2ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…)
"""
    human_prompt_template = """ì•„ë˜ëŠ” ê´€ë¦¬ì ë„êµ¬ ì ê²€ ê²°ê³¼ ë°œê²¬ëœ 'ì ì¬ì  ìœ„í—˜ ìš”ì†Œ'ì™€ 'ì°¸ê³  ë¬¸ì„œ ë‚´ìš©'ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

[ì ì¬ì  ìœ„í—˜ ìš”ì†Œ]
{issue}

[ì°¸ê³  ë¬¸ì„œ ë‚´ìš©]
{context}
"""
    rag_chat_prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", human_prompt_template),
    ])

    # --- Helper í•¨ìˆ˜ ì •ì˜ ---
    def format_docs_for_llm(docs: List[Document]) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ LLM ì…ë ¥ìš© ë‹¨ì¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not docs: return "ê´€ë ¨ëœ ì°¸ê³  ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        formatted_docs = []
        for i, doc in enumerate(docs):
            source_name = os.path.basename(doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ'))
            content_preview = doc.page_content[:300] + ("..." if len(doc.page_content) > 300 else "")
            formatted_docs.append(f"[ë¬¸ì„œ {i+1}: {source_name}]\n{content_preview}\n---")
        return "\n".join(formatted_docs)

    def get_doc_sources(docs: List[Document]) -> List[str]:
        """ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ê³ ìœ í•œ ì†ŒìŠ¤ íŒŒì¼ëª… ëª©ë¡ ì¶”ì¶œ"""
        if not docs: return ["ì—†ìŒ"]
        sources = set(os.path.basename(doc.metadata['source']) for doc in docs if 'source' in doc.metadata)
        return sorted(list(sources)) if sources else ["ì—†ìŒ"]

    # --- LangChain Expression Language (LCEL) íŒŒì´í”„ë¼ì¸ êµ¬ì„± ---
    rag_chain = (
        RunnableParallel(
            {"context": retriever | RunnableLambda(format_docs_for_llm), "issue": RunnablePassthrough()}
        )
        | rag_chat_prompt
        | llm
        | StrOutputParser()
    )

    # --- ê° ì´ìŠˆì— ëŒ€í•´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---
    total_issues = len(issues)
    for i, issue in enumerate(issues):
        print(f"({i+1}/{total_issues}) ì´ìŠˆ ì²˜ë¦¬ ì¤‘: \"{issue[:70]}...\"")
        final_suggestion = f"ì˜¤ë¥˜: ê°œì„  ì œì•ˆ ìƒì„± ë˜ëŠ” ì¶”ì¶œ ì‹¤íŒ¨ (ì´ìŠˆ: {issue[:30]}...)." # ê¸°ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€
        source_list = ["ì˜¤ë¥˜"]

        try:
            # 1. RAG Chain ì‹¤í–‰
            raw_llm_output = rag_chain.invoke(issue)
            raw_llm_output_stripped = raw_llm_output.strip()

            # --- (ë””ë²„ê¹…ìš©) ë¡œê¹…: ì›ë³¸ ì¶œë ¥ í™•ì¸ ---
            # print(f"    --- LLM Raw Output Start ---")
            # print(raw_llm_output_stripped)
            # print(f"    --- LLM Raw Output End ---")
            # ---------------------------------

            # 2. LLM ì¶œë ¥ í›„ì²˜ë¦¬ (assistant ë§ˆì»¤ ê¸°ì¤€ ë¶„ë¦¬ ë° ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš©)
            parts = raw_llm_output_stripped.split(ASSISTANT_MARKER) # ASSISTANT_MARKER = "assistant"

            if len(parts) > 1:
                # ë§ˆì»¤ê°€ í•˜ë‚˜ ì´ìƒ ì¡´ì¬í•˜ë©´, ë§ˆì§€ë§‰ ë§ˆì»¤ ì´í›„ë¥¼ ë‹µë³€ìœ¼ë¡œ ê°„ì£¼
                extracted_content = parts[-1].strip()
                extracted_content = re.sub(r"^\s*[\r\n]+", "", extracted_content) # ì‹œì‘ ê°œí–‰ ì œê±°
                print(f"    -> ì •ë³´: '{ASSISTANT_MARKER}' ë§ˆì»¤ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬, ë§ˆì§€ë§‰ ë¶€ë¶„ ì¶”ì¶œ ì‹œë„.")

                # Stop Token ì”ì—¬ë¬¼ ì œê±°
                stop_strings_used = ["<|endofturn|>", "<|stop|>"]
                final_suggestion = extracted_content
                original_length = len(final_suggestion)
                for stop_str in stop_strings_used:
                    if final_suggestion.endswith(stop_str):
                        final_suggestion = final_suggestion[:-len(stop_str)].rstrip()
                if len(final_suggestion) < original_length:
                    print(f"    -> ì •ë³´: ì¶”ì¶œëœ ë‚´ìš© ëì˜ Stop Token ì œê±°ë¨.")
                print(f"    -> ê°œì„  ì œì•ˆ ë‚´ìš© ì¶”ì¶œ ì™„ë£Œ.")

            else:
                # ASSISTANT_MARKERë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° (ëª¨ë¸ì´ ì—ì½”ì‰ ì‹œ ë§ˆì»¤ë¥¼ í¬í•¨ ì•ˆ í•  ìˆ˜ë„ ìˆìŒ)
                print(f"    -> ê²½ê³ : ì¶œë ¥ì—ì„œ '{ASSISTANT_MARKER}' ë§ˆì»¤ë¥¼ ì°¾ì§€ ëª»í•¨. ì›ë³¸ ì‚¬ìš© ì‹œë„.")
                # ì´ ê²½ìš°, ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ ì§€ì‹œë¥¼ ë”°ë¼ '[ê°œì„  ë°©ì•ˆ 1]'ë¡œ ì‹œì‘í–ˆì„ ê°€ëŠ¥ì„± ê³ ë ¤
                answer_start_pattern = "[ê°œì„  ë°©ì•ˆ 1]"
                start_pos = raw_llm_output_stripped.rfind(answer_start_pattern)
                if start_pos != -1:
                     extracted_content = raw_llm_output_stripped[start_pos:].strip()
                     print(f"    -> ì •ë³´: ëŒ€ì‹  '{answer_start_pattern}' íŒ¨í„´ ê¸°ë°˜ìœ¼ë¡œ ë‚´ìš© ì¶”ì¶œ ì„±ê³µ.")
                     # Stop Token ì œê±°
                     stop_strings_used = ["<|endofturn|>", "<|stop|>"]
                     final_suggestion = extracted_content
                     original_length = len(final_suggestion)
                     for stop_str in stop_strings_used:
                         if final_suggestion.endswith(stop_str):
                             final_suggestion = final_suggestion[:-len(stop_str)].rstrip()
                     if len(final_suggestion) < original_length:
                          print(f"    -> ì •ë³´: ì¶”ì¶œëœ ë‚´ìš© ëì˜ Stop Token ì œê±°ë¨.")
                else:
                    # ë§ˆì»¤ë„, íŒ¨í„´ë„ ëª» ì°¾ìœ¼ë©´ ì˜¤ë¥˜ ì²˜ë¦¬
                    print(f"    -> ì˜¤ë¥˜: '{ASSISTANT_MARKER}' ë§ˆì»¤ ë° '{answer_start_pattern}' íŒ¨í„´ ëª¨ë‘ ì°¾ì§€ ëª»í•¨.")
                    final_suggestion = f"ì˜¤ë¥˜: AI ì‘ë‹µì—ì„œ ì˜ˆìƒëœ êµ¬ë¶„ì('{ASSISTANT_MARKER}') ë˜ëŠ” ì‹œì‘ íŒ¨í„´('{answer_start_pattern}')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


            # 3. ì°¸ê³  ë¬¸ì„œ ëª©ë¡ ì¶”ì¶œ
            retrieved_docs_for_source = retriever.invoke(issue)
            source_list = get_doc_sources(retrieved_docs_for_source)
            print(f"    -> ì°¸ê³  ë¬¸ì„œ: {', '.join(source_list)}")


        except Exception as e:
            print(f"ì˜¤ë¥˜: '{issue[:70]}...' ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ - {e}")
            traceback.print_exc()
            final_suggestion = f"ì˜¤ë¥˜ ë°œìƒ: ê°œì„  ì œì•ˆ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ ({type(e).__name__})."
            source_list = ["ì˜¤ë¥˜ ë°œìƒ"]

        # ìµœì¢… ê²°ê³¼ í¬ë§·íŒ… ë° ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        result_string = f"**[ë¬¸ì œì ]**{issue}|||**[ê°œì„  ì œì•ˆ]**{final_suggestion}|||**[ì°¸ê³  ë¬¸ì„œ]**{','.join(source_list)}"
        suggestions_with_sources.append(result_string)

    print("-" * 50)
    print("ê°œì„  ì œì•ˆ ìƒì„± ì™„ë£Œ.")
    print("-" * 50)
    return suggestions_with_sources

# --- 7. HTML ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜ ---
def export_report_to_html(admin_data: Dict[str, Any], pii_grade: str, system_importance: str, suggestions_data: List[str], filename: str):
    """ë¶„ì„ ê²°ê³¼ ë° ê°œì„  ì œì•ˆì„ HTML íŒŒì¼ë¡œ ì €ì¥."""
    print(f"\nHTML ë³´ê³ ì„œ ìƒì„± ì¤‘: '{filename}'")
    try:
        output_dir = os.path.dirname(filename)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"  -> ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")

        menu_name_escaped = html.escape(admin_data.get('menu_name', 'N/A'))
        menu_id_escaped = html.escape(admin_data.get('menu_id', 'N/A'))
        pii_grade_escaped = html.escape(pii_grade)
        system_importance_escaped = html.escape(system_importance)

        # --- HTML í…œí”Œë¦¿ ---
        html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>Admin Tool ì ê²€ ë³´ê³ ì„œ - {menu_name_escaped}</title>
    <style>
        /* CSS ìŠ¤íƒ€ì¼ ì •ì˜ */
        body {{ font-family: 'Malgun Gothic', 'Segoe UI', sans-serif; line-height: 1.6; margin: 20px; background-color: #f9f9f9; color: #333; }}
        .container {{ max-width: 900px; margin: auto; background: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1, h2, h3 {{ color: #2c3e50; margin-bottom: 15px; padding-bottom: 8px; border-bottom: 2px solid #ecf0f1; }}
        h1 {{ text-align: center; color: #16a085; border-bottom-width: 3px; margin-bottom: 25px; }}
        h2 {{ font-size: 1.5em; margin-top: 25px; }}
        h3 {{ font-size: 1.15em; border-bottom: none; color: #3498db; margin-top: 15px; }}
        .section {{ margin-bottom: 30px; }}
        .summary-table {{ width: 100%; border-collapse: collapse; margin-bottom: 15px; }}
        .summary-table th, .summary-table td {{ border: 1px solid #ddd; padding: 10px; text-align: left; vertical-align: top; }}
        .summary-table th {{ background-color: #f2f2f2; font-weight: bold; width: 30%; }}
        .issue-block {{ margin-bottom: 25px; padding: 18px; border: 1px solid #e0e0e0; border-left: 5px solid #e74c3c; background-color: #fff; border-radius: 5px; }}
        .issue-block h3 {{ margin-top: 0; }}
        .issue-title {{ color: #c0392b; }}
        .suggestion-title {{ color: #2980b9; }}
        .sources-title {{ color: #27ae60; font-size: 1.0em; }}
        .ai-suggestion-marker {{ font-size: 0.8em; color: #7f8c8d; font-style: italic; display: inline-block; margin-left: 8px; }}
        .suggestion-text {{ margin-top: 10px; margin-bottom: 15px; white-space: pre-wrap; background-color: #fdfdfd; padding: 15px; border-radius: 4px; border: 1px dashed #eee; font-size: 0.95em; }}
        .source-list {{ list-style: disc; padding-left: 25px; margin-top: 8px; font-size: 0.9em; color: #555; }}
        .source-list li {{ margin-bottom: 5px; }}
        code {{ background-color: #eee; padding: 2px 5px; border-radius: 3px; font-family: Consolas, Monaco, monospace; border: 1px solid #ddd; color: #c7254e; }}
        hr {{ border: none; border-top: 1px dashed #ccc; margin: 20px 0; }}
        .no-issues {{ color: #777; font-style: italic; padding: 15px; background-color: #f8f8f8; border: 1px solid #eee; border-radius: 4px; text-align: center; }}
        .disclaimer {{ font-size: 0.85em; color: #e74c3c; margin-top: 30px; padding: 15px; background-color: #fff3f3; border: 1px solid #fdd; border-radius: 4px; text-align: center; }}
        .disclaimer strong {{ color: #c0392b; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>Admin Tool ê°œì¸ì •ë³´ ì²˜ë¦¬ í˜„í™© ì ê²€ ë³´ê³ ì„œ</h1>
        <p style="text-align:center; font-size:0.9em; color:#777;">(ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})</p>

        <div class="section">
            <h2>1. ì ê²€ ëŒ€ìƒ ì •ë³´</h2>
            <table class="summary-table">
                <tr><th>ë©”ë‰´ëª…</th><td>{menu_name_escaped}</td></tr>
                <tr><th>ë©”ë‰´ ID</th><td><code>{menu_id_escaped}</code></td></tr>
            </table>
        </div>

        <div class="section">
            <h2>2. ë¶„ì„ ê²°ê³¼ ìš”ì•½ (ì˜ˆë¹„ ì§„ë‹¨)</h2>
             <table class="summary-table">
                <tr><th>ì²˜ë¦¬ ê°œì¸ì •ë³´ ë¯¼ê°ë„ ë“±ê¸‰ (ì˜ˆì‹œ)</th><td>{pii_grade_escaped}</td></tr>
                <tr><th>ì‹œìŠ¤í…œ ì¤‘ìš”ë„ (ì˜ˆì‹œ)</th><td>{system_importance_escaped}</td></tr>
            </table>
        </div>

        <div class="section">
            <h2>3. ì ì¬ì  ìœ„í—˜ ìš”ì†Œ ë° ê°œì„  ì œì•ˆ (AI ê¸°ë°˜)</h2>
"""
        # --- ê°œì„  ì œì•ˆ ì„¹ì…˜ ë™ì  ìƒì„± ---
        if not suggestions_data:
            html_content += '<p class="no-issues">ì ê²€ ê²°ê³¼ íŠ¹ì´ì‚¬í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ì˜ˆì‹œ ë¡œì§ ê¸°ì¤€).</p>'
        else:
            for idx, data_block in enumerate(suggestions_data):
                parts = data_block.split("|||", 2)
                issue_text = html.escape(parts[0].replace("**[ë¬¸ì œì ]**", "").strip()) if len(parts) > 0 else "N/A"
                suggestion_raw = parts[1].replace("**[ê°œì„  ì œì•ˆ]**", "").strip() if len(parts) > 1 else "N/A"
                source_info = parts[2].replace("**[ì°¸ê³  ë¬¸ì„œ]**", "").strip() if len(parts) > 2 else ""
                formatted_suggestion_html = html.escape(suggestion_raw).replace('\n', '<br>')
                source_list_items = ""
                if source_info and source_info.lower() != "ì—†ìŒ" and source_info.lower() != "ì˜¤ë¥˜ ë°œìƒ":
                    sources = [html.escape(s.strip()) for s in source_info.split(',') if s.strip()]
                    source_list_items = "".join(f"<li>{s}</li>" for s in sources)
                elif source_info.lower() == "ì—†ìŒ":
                     source_list_items = "<li>ê´€ë ¨ ì°¸ê³  ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.</li>"
                else: # ì˜¤ë¥˜ ë“±
                     source_list_items = f"<li>{html.escape(source_info)}</li>"

                html_content += f"""
            <div class="issue-block">
                <h3 class="issue-title">ğŸ“Œ ë¬¸ì œì  {idx+1}</h3>
                <p>{issue_text}</p>
                <hr>
                <h3 class="suggestion-title">ğŸ’¡ ê°œì„  ì œì•ˆ <span class="ai-suggestion-marker">(AI ìƒì„±)</span></h3>
                <div class="suggestion-text">{formatted_suggestion_html}</div>
                """
                if source_list_items:
                    html_content += f"""
                <h3 class="sources-title">ğŸ“š ì°¸ê³  ë¬¸ì„œ (RAG ê²€ìƒ‰ ê²°ê³¼)</h3>
                <ul class="source-list">
                    {source_list_items}
                </ul>
                """
                html_content += "            </div>\n"

        # --- HTML ë§ˆë¬´ë¦¬ ---
        html_content += """
        </div>
        <div class="disclaimer">
            <strong>!!!ì¤‘ìš”!!!:</strong> ë³¸ ë³´ê³ ì„œì˜ 'ê°œì„  ì œì•ˆ' ë‚´ìš©ì€ AI(LLM)ì— ì˜í•´ ìƒì„±ëœ ì´ˆì•ˆìœ¼ë¡œ, ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            ì œì•ˆ ë‚´ìš©ì€ ë¶€ì •í™•í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì œ ì ìš© ì „ ë°˜ë“œì‹œ ê´€ë ¨ ë²•ê·œ, ë‚´ë¶€ ì •ì±…, ì‹œìŠ¤í…œ í™˜ê²½ ë“±ì„ ê³ ë ¤í•˜ì—¬ ì „ë¬¸ê°€ ë° 
            ë‹´ë‹¹ ë¶€ì„œì˜ ê²€í† ì™€ ìŠ¹ì¸ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤. AI ìƒì„± ë‚´ìš©ì— ê¸°ë°˜í•œ ê²°ì •ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ëª¨ë“  ê²°ê³¼ì— ëŒ€í•´ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.
        </div>
    </div>
</body>
</html>
"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"HTML ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: '{os.path.abspath(filename)}'")

    except Exception as e:
        print(f"ì˜¤ë¥˜: HTML ë³´ê³ ì„œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ - {e}")
        traceback.print_exc()


# --- 8. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ---
if __name__ == "__main__":
    print("=" * 60)
    print(" ê°œì¸ì •ë³´ ì²˜ë¦¬ ì‹œìŠ¤í…œ(Admin Tool) ì ê²€ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸")
    print(" (RAG + LLM ê¸°ë°˜ ê°œì„  ì œì•ˆ ìë™í™”)")
    print("=" * 60)

    # 1. ì…ë ¥ JSON ë¡œë“œ
    print(f"\n[ë‹¨ê³„ 1/6] ì…ë ¥ ë°ì´í„° ë¡œë”© ({INPUT_JSON_FILE})")
    if not os.path.exists(INPUT_JSON_FILE):
        print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ '{INPUT_JSON_FILE}' ì—†ìŒ. ìƒ˜í”Œ íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        sample_data = { "menu_id": "sample_user_manage", "menu_name": "ìƒ˜í”Œ ì‚¬ìš©ì ê´€ë¦¬", "fields": [{"field_name": "user_id", "pii_type": "id", "visible": True, "masked": True}, {"field_name": "user_name", "pii_type": "name", "visible": True, "masked": False}, {"field_name": "email", "pii_type": "email", "visible": True, "masked": True}], "actions": [{"action_name": "view_detail", "enabled": True, "required_permission": "view_user"}, {"action_name": "modify_user_info", "enabled": True, "required_permission": "update_user"}, {"action_name": "download_user_list", "enabled": True, "required_permission": "download_user", "download_encryption": None}]}
        try:
            with open(INPUT_JSON_FILE, 'w', encoding='utf-8') as f_sample: json.dump(sample_data, f_sample, indent=4, ensure_ascii=False)
            print(f"    -> ì •ë³´: ì…ë ¥ íŒŒì¼ì´ ì—†ì–´ ìƒ˜í”Œ '{INPUT_JSON_FILE}' ìƒì„± ì™„ë£Œ.")
            admin_tool_data = sample_data
        except Exception as e_create: print(f"    -> ì˜¤ë¥˜: ìƒ˜í”Œ ì…ë ¥ íŒŒì¼ ìƒì„± ì‹¤íŒ¨ - {e_create}. ì¢…ë£Œí•©ë‹ˆë‹¤."); exit(1)
    else:
        try:
            with open(INPUT_JSON_FILE, 'r', encoding='utf-8') as f: admin_tool_data = json.load(f)
            print(" -> ë¡œë”© ì™„ë£Œ.")
        except Exception as e: print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ ë¡œë“œ/íŒŒì‹± ì‹¤íŒ¨ - {e}. ì¢…ë£Œí•©ë‹ˆë‹¤."); exit(1)

    if not isinstance(admin_tool_data, dict) or not admin_tool_data.get("menu_id"):
         print("ì˜¤ë¥˜: ì…ë ¥ ë°ì´í„°ê°€ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹ˆê±°ë‚˜ í•„ìˆ˜ í‚¤('menu_id')ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤."); exit(1)


    # 2. ëª¨ë¸ ë¡œë”©
    print(f"\n[ë‹¨ê³„ 2/6] AI ëª¨ë¸ ë¡œë”©")
    llm, embedding_model, tokenizer = load_models()
    if not llm or not embedding_model or not tokenizer:
        print("ì˜¤ë¥˜: AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)
    print(" -> ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

    # 3. RAG ì„¤ì •
    print(f"\n[ë‹¨ê³„ 3/6] RAG ì„¤ì • (ë¬¸ì„œ ê¸°ë°˜ ê°œì„ ì•ˆ ë„ì¶œ ì¤€ë¹„)")
    retriever = setup_rag_retriever(embedding_model)
    if not retriever:
         print("ê²½ê³ : RAG Retriever ì„¤ì • ì‹¤íŒ¨ ë˜ëŠ” ë¬¸ì„œ ì—†ìŒ. ë¬¸ì„œ ì°¸ì¡° ì—†ëŠ” ë¶„ì„/ì œì•ˆìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
         print(" -> RAG ì„¤ì • ì™„ë£Œ.")

    # 4. ë°ì´í„° ë¶„ì„ (ì˜ˆì‹œ ë¡œì§ ê¸°ë°˜)
    print("\n[ë‹¨ê³„ 4/6] ì…ë ¥ ë°ì´í„° ë¶„ì„ (ì˜ˆë¹„ ì§„ë‹¨ ìˆ˜í–‰)")
    pii_grade = analyze_pii_grade(admin_tool_data.get("fields", []))
    system_importance = analyze_system_importance(admin_tool_data.get("actions", []), pii_grade)
    potential_issues = identify_potential_issues(admin_tool_data.get("fields", []), admin_tool_data.get("actions", []))
    print(f" -> ì˜ˆë¹„ ì§„ë‹¨ ì™„ë£Œ: ë¯¼ê°ë„='{pii_grade}', ì¤‘ìš”ë„='{system_importance}', ì ì¬ ì´ìŠˆ={len(potential_issues)}ê°œ ì‹ë³„ë¨.")
    if not potential_issues:
        print(" -> ì •ë³´: ì˜ˆì‹œ ë¡œì§ ê¸°ì¤€, íŠ¹ì´í•œ ì ì¬ ìœ„í—˜ ìš”ì†ŒëŠ” ì‹ë³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # 5. ê°œì„ ì‚¬í•­ ìƒì„± (RAG + LLM)
    print("\n[ë‹¨ê³„ 5/6] ê°œì„  ì œì•ˆ ìƒì„± (AI í™œìš©)")
    suggestions_with_sources = generate_improvement_suggestions(potential_issues, retriever, llm, tokenizer)
    print(f" -> AI ê¸°ë°˜ ê°œì„  ì œì•ˆ {len(suggestions_with_sources)}ê°œ ìƒì„± ì™„ë£Œ.")

    # 6. HTML ë³´ê³ ì„œ ì €ì¥
    print("\n[ë‹¨ê³„ 6/6] ìµœì¢… ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥")
    menu_id = admin_tool_data.get('menu_id', 'unknown_menu')
    safe_menu_id = re.sub(r'[\\/*?:"<>|]', "_", menu_id)
    report_filename = os.path.join(OUTPUT_DIR, f"AdminTool_Check_Report_{safe_menu_id}_{datetime.now().strftime('%Y%m%d')}.html")
    export_report_to_html(admin_tool_data, pii_grade, system_importance, suggestions_with_sources, report_filename)

    print("\n" + "=" * 60)
    print(" ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ")
    print("=" * 60)